b"Help:\r\nHelp for AbstractTask\r\n\r\n== Cost-adapted task ==\r\nadapt_costs(cost_type=normal)\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n== no_transform ==\r\nno_transform()\r\n\r\nHelp for ConstraintGenerator\r\n\r\n== Delete relaxation constraints ==\r\ndelete_relaxation_constraints(use_time_vars=false, use_integer_vars=false)\r\n use_time_vars (bool): use variables for time steps. With these additional variables the constraints enforce an order between the selected operators. Leaving this off (default) corresponds to the time relaxation by Imai and Fukunaga. Switching it on, can increase the heuristic value but will increase the size of the constraints which has a strong impact on runtime. Constraints involving time variables use a big-M encoding, so they are more useful if used with integer variables.\r\n use_integer_vars (bool): restrict auxiliary variables to integer values. These variables encode whether operators are used, facts are reached, which operator first achieves which fact, and in which order the operators are used. Restricting them to integers generally improves the heuristic value at the cost of increased runtime.\r\n== LM-cut landmark constraints ==\r\nlmcut_constraints()\r\n== Posthoc optimization constraints ==\r\npho_constraints(patterns=systematic(2))\r\n patterns (PatternCollectionGenerator): pattern generation method\r\n== State equation constraints ==\r\nstate_equation_constraints(verbosity=normal)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n\r\nHelp for Evaluator\r\n\r\n\r\nThis feature type can be bound to variables using ``let(variable_name, variable_definition, expression)`` where ``expression`` can use ``variable_name``. Predefinitions using ``--evaluator``, ``--heuristic``, and ``--landmarks`` are automatically transformed into ``let``-expressions but are deprecated.\r\n== Additive heuristic ==\r\nadd(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Blind heuristic ==\r\nblind(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Context-enhanced additive heuristic ==\r\ncea(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Additive Cartesian CEGAR heuristic ==\r\ncegar(subtasks=[landmarks(),goals()], max_states=infinity, max_transitions=1M, max_time=infinity, pick=max_refined, use_general_costs=true, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1)\r\n subtasks (list of SubtaskGenerator): subtask generators\r\n max_states (int [1, infinity]): maximum sum of abstract states over all abstractions\r\n max_transitions (int [0, infinity]): maximum sum of real transitions (excluding self-loops) over  all abstractions\r\n max_time (double [0.0, infinity]): maximum time in seconds for building abstractions\r\n pick ({random, min_unwanted, max_unwanted, min_refined, max_refined, min_hadd, max_hadd}): how to choose on which variable to split the flaw state\r\n - random: select a random variable (among all eligible variables)\r\n - min_unwanted: select an eligible variable which has the least unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state\r\n - max_unwanted: select an eligible variable which has the most unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state\r\n - min_refined: select an eligible variable which is the least refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state\r\n - max_refined: select an eligible variable which is the most refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state\r\n - min_hadd: select an eligible variable with minimal h^add(s_0) value over all facts that need to be removed from the flaw state\r\n - max_hadd: select an eligible variable with maximal h^add(s_0) value over all facts that need to be removed from the flaw state\r\n use_general_costs (bool): allow negative costs in cost partitioning\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== Causal graph heuristic ==\r\ncg(max_cache_size=1000000, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n max_cache_size (int [0, infinity]): maximum number of cached entries per variable (set to 0 to disable cache)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== FF heuristic ==\r\nff(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Goal count heuristic ==\r\ngoalcount(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== h^m heuristic ==\r\nhm(m=2, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n m (int [1, infinity]): subset size\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Max heuristic ==\r\nhmax(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Landmark cost partitioning heuristic ==\r\nlandmark_cost_partitioning(lm_factory, pref=false, prog_goal=true, prog_gn=true, prog_r=true, verbosity=normal, transform=no_transform(), cache_estimates=true, cost_partitioning=uniform, alm=true, lpsolver=cplex)\r\n lm_factory (LandmarkFactory): the set of landmarks to use for this heuristic. The set of landmarks can be specified here, or predefined (see LandmarkFactory).\r\n pref (bool): enable preferred operators (see note below)\r\n prog_goal (bool): Use goal progression.\r\n prog_gn (bool): Use greedy-necessary ordering progression.\r\n prog_r (bool): Use reasonable ordering progression.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n cost_partitioning ({optimal, uniform}): strategy for partitioning operator costs among landmarks\r\n - optimal: use optimal (LP-based) cost partitioning\r\n - uniform: partition operator costs uniformly among all landmarks achieved by that operator\r\n alm (bool): use action landmarks\r\n lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs\r\n - cplex: commercial solver by IBM\r\n - soplex: open source solver by ZIB\r\n== Landmark sum heuristic ==\r\nlandmark_sum(lm_factory, pref=false, prog_goal=true, prog_gn=true, prog_r=true, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n lm_factory (LandmarkFactory): the set of landmarks to use for this heuristic. The set of landmarks can be specified here, or predefined (see LandmarkFactory).\r\n pref (bool): enable preferred operators (see note below)\r\n prog_goal (bool): Use goal progression.\r\n prog_gn (bool): Use greedy-necessary ordering progression.\r\n prog_r (bool): Use reasonable ordering progression.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Landmark-cut heuristic ==\r\nlmcut(verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Merge-and-shrink heuristic ==\r\nmerge_and_shrink(verbosity=normal, transform=no_transform(), cache_estimates=true, merge_strategy, shrink_strategy, label_reduction=<none>, prune_unreachable_states=true, prune_irrelevant_states=true, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, main_loop_max_time=infinity)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n merge_strategy (MergeStrategy): See detailed documentation for merge strategies. We currently recommend SCC-DFP, which can be achieved using {{{merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order]))}}}\r\n shrink_strategy (ShrinkStrategy): See detailed documentation for shrink strategies. We currently recommend non-greedy shrink_bisimulation, which can be achieved using {{{shrink_strategy=shrink_bisimulation(greedy=false)}}}\r\n label_reduction (LabelReduction): See detailed documentation for labels. There is currently only one 'option' to use label_reduction, which is {{{label_reduction=exact}}} Also note the interaction with shrink strategies.\r\n prune_unreachable_states (bool): If true, prune abstract states unreachable from the initial state.\r\n prune_irrelevant_states (bool): If true, prune abstract states from which no goal state can be reached.\r\n max_states (int [-1, infinity]): maximum transition system size allowed at any time point.\r\n max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product.\r\n threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system.\r\n main_loop_max_time (double [0.0, infinity]): A limit in seconds on the runtime of the main loop of the algorithm. If the limit is exceeded, the algorithm terminates, potentially returning a factored transition system with several factors. Also note that the time limit is only checked between transformations of the main loop, but not during, so it can be exceeded if a transformation is runtime-intense.\r\n== Operator-counting heuristic ==\r\noperatorcounting(constraint_generators, use_integer_operator_counts=false, lpsolver=cplex, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n constraint_generators (list of ConstraintGenerator): methods that generate constraints over operator-counting variables\r\n use_integer_operator_counts (bool): restrict operator-counting variables to integer values. Computing the heuristic with integer variables can produce higher values but requires solving a MIP instead of an LP which is generally more computationally expensive. Turning this option on can thus drastically increase the runtime.\r\n lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs\r\n - cplex: commercial solver by IBM\r\n - soplex: open source solver by ZIB\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n\r\n= Basic Evaluators =\r\n\r\n== Constant evaluator ==\r\nconst(value=1, verbosity=normal)\r\n value (int [0, infinity]): the constant value\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== g-value evaluator ==\r\ng(verbosity=normal)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Max evaluator ==\r\nmax(evals, verbosity=normal)\r\n evals (list of Evaluator): at least one evaluator\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Preference evaluator ==\r\npref(verbosity=normal)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Sum evaluator ==\r\nsum(evals, verbosity=normal)\r\n evals (list of Evaluator): at least one evaluator\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Weighted evaluator ==\r\nweight(eval, weight, verbosity=normal)\r\n eval (Evaluator): evaluator\r\n weight (int): weight\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n\r\n= Pattern Database Heuristics =\r\n\r\n== Canonical PDB ==\r\ncpdbs(patterns=systematic(1), max_time_dominance_pruning=infinity, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n patterns (PatternCollectionGenerator): pattern generation method\r\n max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== iPDB ==\r\nipdb(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, random_seed=-1, max_time_dominance_pruning=infinity, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n pdb_max_size (int [1, infinity]): maximal number of states per pattern database \r\n collection_max_size (int [1, infinity]): maximal number of states in the pattern collection\r\n num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection\r\n min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection \r\n max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns.\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Pattern database heuristic ==\r\npdb(pattern=greedy(), verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n pattern (PatternGenerator): pattern generation method\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Zero-One PDB ==\r\nzopdbs(patterns=systematic(1), verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n patterns (PatternCollectionGenerator): pattern generation method\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n\r\n= Potential Heuristics =\r\n\r\n== Potential heuristic optimized for all states ==\r\nall_states_potential(max_potential=1e8, lpsolver=cplex, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound {{{infinity}}} disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.\r\n lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs\r\n - cplex: commercial solver by IBM\r\n - soplex: open source solver by ZIB\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Diverse potential heuristics ==\r\ndiverse_potentials(num_samples=1000, max_num_heuristics=infinity, max_potential=1e8, lpsolver=cplex, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1)\r\n num_samples (int [0, infinity]): Number of states to sample\r\n max_num_heuristics (int [0, infinity]): maximum number of potential heuristics\r\n max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound {{{infinity}}} disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.\r\n lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs\r\n - cplex: commercial solver by IBM\r\n - soplex: open source solver by ZIB\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== Potential heuristic optimized for initial state ==\r\ninitial_state_potential(max_potential=1e8, lpsolver=cplex, verbosity=normal, transform=no_transform(), cache_estimates=true)\r\n max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound {{{infinity}}} disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.\r\n lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs\r\n - cplex: commercial solver by IBM\r\n - soplex: open source solver by ZIB\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n== Sample-based potential heuristics ==\r\nsample_based_potentials(num_heuristics=1, num_samples=1000, max_potential=1e8, lpsolver=cplex, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1)\r\n num_heuristics (int [0, infinity]): number of potential heuristics\r\n num_samples (int [0, infinity]): Number of states to sample\r\n max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound {{{infinity}}} disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.\r\n lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs\r\n - cplex: commercial solver by IBM\r\n - soplex: open source solver by ZIB\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.\r\n cache_estimates (bool): cache heuristic estimates\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n\r\nHelp for LabelReduction\r\n\r\n== Exact generalized label reduction ==\r\nexact(before_shrinking, before_merging, method=all_transition_systems_with_fixpoint, system_order=random, random_seed=-1)\r\n before_shrinking (bool): apply label reduction before shrinking\r\n before_merging (bool): apply label reduction before merging\r\n method ({two_transition_systems, all_transition_systems, all_transition_systems_with_fixpoint}): Label reduction method. See the AAAI14 paper by Sievers et al. for explanation of the default label reduction method and the 'combinable relation' .Also note that you must set at least one of the options reduce_labels_before_shrinking or reduce_labels_before_merging in order to use the chosen label reduction configuration.\r\n - two_transition_systems: compute the 'combinable relation' only for the two transition systems being merged next\r\n - all_transition_systems: compute the 'combinable relation' for labels once for every transition system and reduce labels\r\n - all_transition_systems_with_fixpoint: keep computing the 'combinable relation' for labels iteratively for all transition systems until no more labels can be reduced\r\n system_order ({regular, reverse, random}): Order of transition systems for the label reduction methods that iterate over the set of all transition systems. Only useful for the choices all_transition_systems and all_transition_systems_with_fixpoint for the option label_reduction_method.\r\n - regular: transition systems are considered in the order given in the planner input if atomic and in the order of their creation if composite.\r\n - reverse: inverse of regular\r\n - random: random order\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n\r\nHelp for LandmarkFactory\r\n\r\n\r\nThis feature type can be bound to variables using ``let(variable_name, variable_definition, expression)`` where ``expression`` can use ``variable_name``. Predefinitions using ``--evaluator``, ``--heuristic``, and ``--landmarks`` are automatically transformed into ``let``-expressions but are deprecated.\r\n== Exhaustive Landmarks ==\r\nlm_exhaust(verbosity=normal, only_causal_landmarks=false)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n only_causal_landmarks (bool): keep only causal landmarks\r\n== h^m Landmarks ==\r\nlm_hm(m=2, conjunctive_landmarks=true, verbosity=normal, use_orders=true)\r\n m (int): subset size (if unsure, use the default of 2)\r\n conjunctive_landmarks (bool): keep conjunctive landmarks\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n use_orders (bool): use orders between landmarks\r\n== Merged Landmarks ==\r\nlm_merged(lm_factories, verbosity=normal)\r\n lm_factories (list of LandmarkFactory): \r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== HPS Orders ==\r\nlm_reasonable_orders_hps(lm_factory, verbosity=normal)\r\n lm_factory (LandmarkFactory): \r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== RHW Landmarks ==\r\nlm_rhw(disjunctive_landmarks=true, verbosity=normal, use_orders=true, only_causal_landmarks=false)\r\n disjunctive_landmarks (bool): keep disjunctive landmarks\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n use_orders (bool): use orders between landmarks\r\n only_causal_landmarks (bool): keep only causal landmarks\r\n== Zhu/Givan Landmarks ==\r\nlm_zg(verbosity=normal, use_orders=true)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n use_orders (bool): use orders between landmarks\r\n\r\nHelp for MergeScoringFunction\r\n\r\n== DFP scoring ==\r\ndfp()\r\n== Goal relevance scoring ==\r\ngoal_relevance()\r\n== MIASM ==\r\nsf_miasm(shrink_strategy, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, use_caching=true)\r\n shrink_strategy (ShrinkStrategy): We recommend setting this to match the shrink strategy configuration given to {{{merge_and_shrink}}}, see note below.\r\n max_states (int [-1, infinity]): maximum transition system size allowed at any time point.\r\n max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product.\r\n threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system.\r\n use_caching (bool): Cache scores for merge candidates. IMPORTANT! This only works under the assumption that the merge-and-shrink algorithm only uses exact label reduction and does not (non-exactly) shrink factors other than those being merged in the current iteration. In this setting, the MIASM score of a merge candidate is constant over merge-and-shrink iterations. If caching is enabled, only the scores for the new merge candidates need to be computed.\r\n== Single random ==\r\nsingle_random(random_seed=-1)\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== Total order ==\r\ntotal_order(atomic_ts_order=reverse_level, product_ts_order=new_to_old, atomic_before_product=false, random_seed=-1)\r\n atomic_ts_order ({reverse_level, level, random}): The order in which atomic transition systems are considered when considering pairs of potential merges.\r\n - reverse_level: the variable order of Fast Downward\r\n - level: opposite of reverse_level\r\n - random: a randomized order\r\n product_ts_order ({old_to_new, new_to_old, random}): The order in which product transition systems are considered when considering pairs of potential merges.\r\n - old_to_new: consider composite transition systems from oldest to most recent\r\n - new_to_old: opposite of old_to_new\r\n - random: a randomized order\r\n atomic_before_product (bool): Consider atomic transition systems before composite ones iff true.\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n\r\nHelp for MergeSelector\r\n\r\n== Score based filtering merge selector ==\r\nscore_based_filtering(scoring_functions)\r\n scoring_functions (list of MergeScoringFunction): The list of scoring functions used to compute scores for candidates.\r\n\r\nHelp for MergeStrategy\r\n\r\n== Precomputed merge strategy ==\r\nmerge_precomputed(merge_tree, verbosity=normal)\r\n merge_tree (MergeTree): The precomputed merge tree.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Merge strategy SSCs ==\r\nmerge_sccs(order_of_sccs=topological, merge_tree=<none>, merge_selector=<none>, verbosity=normal)\r\n order_of_sccs ({topological, reverse_topological, decreasing, increasing}): how the SCCs should be ordered\r\n - topological: according to the topological ordering of the directed graph where each obtained SCC is a 'supervertex'\r\n - reverse_topological: according to the reverse topological ordering of the directed graph where each obtained SCC is a 'supervertex'\r\n - decreasing: biggest SCCs first, using 'topological' as tie-breaker\r\n - increasing: smallest SCCs first, using 'topological' as tie-breaker\r\n merge_tree (MergeTree): the fallback merge strategy to use if a precomputed strategy should be used.\r\n merge_selector (MergeSelector): the fallback merge strategy to use if a stateless strategy should be used.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Stateless merge strategy ==\r\nmerge_stateless(merge_selector, verbosity=normal)\r\n merge_selector (MergeSelector): The merge selector to be used.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n\r\nHelp for MergeTree\r\n\r\n== Linear merge trees ==\r\nlinear(random_seed=-1, update_option=use_random, variable_order=cg_goal_level)\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n update_option ({use_first, use_second, use_random}): When the merge tree is used within another merge strategy, how should it be updated when a merge different to a merge from the tree is performed.\r\n - use_first: the node representing the index that would have been merged earlier survives\r\n - use_second: the node representing the index that would have been merged later survives\r\n - use_random: a random node (of the above two) survives\r\n variable_order ({cg_goal_level, cg_goal_random, goal_cg_level, random, level, reverse_level}): the order in which atomic transition systems are merged\r\n - cg_goal_level: variables are prioritized first if they have an arc to a previously added variable, second if their goal value is defined and third according to their level in the causal graph\r\n - cg_goal_random: variables are prioritized first if they have an arc to a previously added variable, second if their goal value is defined and third randomly\r\n - goal_cg_level: variables are prioritized first if their goal value is defined, second if they have an arc to a previously added variable, and third according to their level in the causal graph\r\n - random: variables are ordered randomly\r\n - level: variables are ordered according to their level in the causal graph\r\n - reverse_level: variables are ordered reverse to their level in the causal graph\r\n\r\nHelp for OpenList\r\n\r\n== Alternation open list ==\r\nalt(sublists, boost=0)\r\n sublists (list of OpenList): open lists between which this one alternates\r\n boost (int): boost value for contained open lists that are restricted to preferred successors\r\n== Epsilon-greedy open list ==\r\nepsilon_greedy(eval, pref_only=false, epsilon=0.2, random_seed=-1)\r\n eval (Evaluator): evaluator\r\n pref_only (bool): insert only nodes generated by preferred operators\r\n epsilon (double [0.0, 1.0]): probability for choosing the next entry randomly\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== Pareto open list ==\r\npareto(evals, pref_only=false, state_uniform_selection=false, random_seed=-1)\r\n evals (list of Evaluator): evaluators\r\n pref_only (bool): insert only nodes generated by preferred operators\r\n state_uniform_selection (bool): When removing an entry, we select a non-dominated bucket and return its oldest entry. If this option is false, we select uniformly from the non-dominated buckets; if the option is true, we weight the buckets with the number of entries.\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== Best-first open list ==\r\nsingle(eval, pref_only=false)\r\n eval (Evaluator): evaluator\r\n pref_only (bool): insert only nodes generated by preferred operators\r\n== Tie-breaking open list ==\r\ntiebreaking(evals, pref_only=false, unsafe_pruning=true)\r\n evals (list of Evaluator): evaluators\r\n pref_only (bool): insert only nodes generated by preferred operators\r\n unsafe_pruning (bool): allow unsafe pruning when the main evaluator regards a state a dead end\r\n== Type-based open list ==\r\ntype_based(evaluators, random_seed=-1)\r\n evaluators (list of Evaluator): Evaluators used to determine the bucket for each entry.\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n\r\nHelp for PatternCollectionGenerator\r\n\r\n== combo ==\r\ncombo(max_states=1000000, verbosity=normal)\r\n max_states (int [1, infinity]): maximum abstraction size for combo strategy\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Disjoint CEGAR ==\r\ndisjoint_cegar(max_pdb_size=1000000, max_collection_size=10000000, max_time=infinity, use_wildcard_plans=true, verbosity=normal, random_seed=-1)\r\n max_pdb_size (int [1, infinity]): maximum number of states per pattern database (ignored for the initial collection consisting of a singleton pattern for each goal variable)\r\n max_collection_size (int [1, infinity]): maximum number of states in the pattern collection (ignored for the initial collection consisting of a singleton pattern for each goal variable)\r\n max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator (ignored for computing the initial collection consisting of a singleton pattern for each goal variable)\r\n use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== Genetic Algorithm Patterns ==\r\ngenetic(pdb_max_size=50000, num_collections=5, num_episodes=30, mutation_probability=0.01, disjoint=false, random_seed=-1, verbosity=normal)\r\n pdb_max_size (int [1, infinity]): maximal number of states per pattern database \r\n num_collections (int [1, infinity]): number of pattern collections to maintain in the genetic algorithm (population size)\r\n num_episodes (int [0, infinity]): number of episodes for the genetic algorithm\r\n mutation_probability (double [0.0, 1.0]): probability for flipping a bit in the genetic algorithm\r\n disjoint (bool): consider a pattern collection invalid (giving it very low fitness) if its patterns are not disjoint\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Hill climbing ==\r\nhillclimbing(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, random_seed=-1, verbosity=normal)\r\n pdb_max_size (int [1, infinity]): maximal number of states per pattern database \r\n collection_max_size (int [1, infinity]): maximal number of states in the pattern collection\r\n num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection\r\n min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection \r\n max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns.\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== manual_patterns ==\r\nmanual_patterns(patterns, verbosity=normal)\r\n patterns (list of list of int): list of patterns (which are lists of variable numbers of the planning task).\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Multiple CEGAR ==\r\nmultiple_cegar(max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, verbosity=normal, random_seed=-1, use_wildcard_plans=true)\r\n max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable)\r\n max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size)\r\n pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern\r\n total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once.\r\n stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled.\r\n blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled\r\n enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators\r\n== Multiple Random Patterns ==\r\nrandom_patterns(max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, verbosity=normal, random_seed=-1, bidirectional=true)\r\n max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable)\r\n max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size)\r\n pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern\r\n total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once.\r\n stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled.\r\n blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled\r\n enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor.\r\n== Systematically generated patterns ==\r\nsystematic(pattern_max_size=1, only_interesting_patterns=true, verbosity=normal)\r\n pattern_max_size (int [1, infinity]): max number of variables per pattern\r\n only_interesting_patterns (bool): Only consider the union of two disjoint patterns if the union has more information than the individual patterns.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n\r\nHelp for PatternGenerator\r\n\r\n== CEGAR ==\r\ncegar_pattern(max_pdb_size=1000000, max_time=infinity, use_wildcard_plans=true, verbosity=normal, random_seed=-1)\r\n max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable)\r\n max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation\r\n use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== greedy ==\r\ngreedy(max_states=1000000, verbosity=normal)\r\n max_states (int [1, infinity]): maximal number of abstract states in the pattern database.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== manual_pattern ==\r\nmanual_pattern(pattern, verbosity=normal)\r\n pattern (list of int): list of variable numbers of the planning task that should be used as pattern.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Random Pattern ==\r\nrandom_pattern(max_pdb_size=1000000, max_time=infinity, bidirectional=true, verbosity=normal, random_seed=-1)\r\n max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable)\r\n max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation\r\n bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n\r\nHelp for PruningMethod\r\n\r\n== Atom-centric stubborn sets ==\r\natom_centric_stubborn_sets(use_sibling_shortcut=true, atom_selection_strategy=quick_skip, verbosity=normal)\r\n use_sibling_shortcut (bool): use variable-based marking in addition to atom-based marking\r\n atom_selection_strategy ({fast_downward, quick_skip, static_small, dynamic_small}): Strategy for selecting unsatisfied atoms from action preconditions or the goal atoms. All strategies use the fast_downward strategy for breaking ties.\r\n - fast_downward: select the atom (v, d) with the variable v that comes first in the Fast Downward variable ordering (which is based on the causal graph)\r\n - quick_skip: if possible, select an unsatisfied atom whose producers are already marked\r\n - static_small: select the atom achieved by the fewest number of actions\r\n - dynamic_small: select the atom achieved by the fewest number of actions that are not yet part of the stubborn set\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Limited pruning ==\r\nlimited_pruning(pruning, min_required_pruning_ratio=0.2, expansions_before_checking_pruning_ratio=1000, verbosity=normal)\r\n pruning (PruningMethod): the underlying pruning method to be applied\r\n min_required_pruning_ratio (double [0.0, 1.0]): disable pruning if the pruning ratio is lower than this value after 'expansions_before_checking_pruning_ratio' expansions\r\n expansions_before_checking_pruning_ratio (int [0, infinity]): number of expansions before deciding whether to disable pruning\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== No pruning ==\r\nnull(verbosity=normal)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== StubbornSetsEC ==\r\nstubborn_sets_ec(verbosity=normal)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Stubborn sets simple ==\r\nstubborn_sets_simple(verbosity=normal)\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n\r\nHelp for SearchAlgorithm\r\n\r\n== A* search (eager) ==\r\nastar(eval, lazy_evaluator=<none>, pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n eval (Evaluator): evaluator for h-value\r\n lazy_evaluator (Evaluator): An evaluator that re-evaluates a state before it is expanded.\r\n pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Eager best-first search ==\r\neager(open, reopen_closed=false, f_eval=<none>, preferred=[], pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n open (OpenList): open list\r\n reopen_closed (bool): reopen closed nodes\r\n f_eval (Evaluator): set evaluator for jump statistics. (Optional; if no evaluator is used, jump statistics will not be displayed.)\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Greedy search (eager) ==\r\neager_greedy(evals, preferred=[], boost=0, pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n evals (list of Evaluator): evaluators\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n boost (int): boost value for preferred operator open lists\r\n pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Eager weighted A* search ==\r\neager_wastar(evals, preferred=[], reopen_closed=true, boost=0, w=1, pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n evals (list of Evaluator): evaluators\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n reopen_closed (bool): reopen closed nodes\r\n boost (int): boost value for preferred operator open lists\r\n w (int): evaluator weight\r\n pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Lazy enforced hill-climbing ==\r\nehc(h, preferred_usage=prune_by_preferred, preferred=[], cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n h (Evaluator): heuristic\r\n preferred_usage ({prune_by_preferred, rank_preferred_first}): preferred operator usage\r\n - prune_by_preferred: prune successors achieved by non-preferred operators\r\n - rank_preferred_first: first insert successors achieved by preferred operators, then those by non-preferred operators\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Iterated search ==\r\niterated(algorithm_configs, pass_bound=true, repeat_last=false, continue_on_fail=false, continue_on_solve=true, cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n algorithm_configs (list of SearchAlgorithm): list of search algorithms for each phase\r\n pass_bound (bool): use bound from previous search. The bound is the real cost of the plan found before, regardless of the cost_type parameter.\r\n repeat_last (bool): repeat last phase of search\r\n continue_on_fail (bool): continue search after no solution found\r\n continue_on_solve (bool): continue search after solution found\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Lazy best-first search ==\r\nlazy(open, reopen_closed=false, preferred=[], randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n open (OpenList): open list\r\n reopen_closed (bool): reopen closed nodes\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n randomize_successors (bool): randomize the order in which successors are generated\r\n preferred_successors_first (bool): consider preferred operators first\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== Greedy search (lazy) ==\r\nlazy_greedy(evals, preferred=[], reopen_closed=false, boost=1000, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n evals (list of Evaluator): evaluators\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n reopen_closed (bool): reopen closed nodes\r\n boost (int): boost value for alternation queues that are restricted to preferred operator nodes\r\n randomize_successors (bool): randomize the order in which successors are generated\r\n preferred_successors_first (bool): consider preferred operators first\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n== (Weighted) A* search (lazy) ==\r\nlazy_wastar(evals, preferred=[], reopen_closed=true, boost=1000, w=1, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=normal, bound=infinity, max_time=infinity, verbosity=normal)\r\n evals (list of Evaluator): evaluators\r\n preferred (list of Evaluator): use preferred operators of these evaluators\r\n reopen_closed (bool): reopen closed nodes\r\n boost (int): boost value for preferred operator open lists\r\n w (int): evaluator weight\r\n randomize_successors (bool): randomize the order in which successors are generated\r\n preferred_successors_first (bool): consider preferred operators first\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.\r\n - normal: all actions are accounted for with their real cost\r\n - one: all actions are accounted for as unit cost\r\n - plusone: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.\r\n bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter\r\n max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.\r\n verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.\r\n - silent: only the most basic output\r\n - normal: relevant information to monitor progress\r\n - verbose: full output\r\n - debug: like verbose with additional debug output\r\n\r\nHelp for ShrinkStrategy\r\n\r\n== Bismulation based shrink strategy ==\r\nshrink_bisimulation(greedy=false, at_limit=return)\r\n greedy (bool): use greedy bisimulation\r\n at_limit ({return, use_up}): what to do when the size limit is hit\r\n - return: stop without refining the equivalence class further\r\n - use_up: continue refining the equivalence class until the size limit is hit\r\n== f-preserving shrink strategy ==\r\nshrink_fh(random_seed=-1, shrink_f=high, shrink_h=low)\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n shrink_f ({high, low}): in which direction the f based shrink priority is ordered\r\n - high: prefer shrinking states with high value\r\n - low: prefer shrinking states with low value\r\n shrink_h ({high, low}): in which direction the h based shrink priority is ordered\r\n - high: prefer shrinking states with high value\r\n - low: prefer shrinking states with low value\r\n== Random ==\r\nshrink_random(random_seed=-1)\r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n\r\nHelp for SubtaskGenerator\r\n\r\n== goals ==\r\ngoals(order=hadd_down, random_seed=-1)\r\n order ({original, random, hadd_up, hadd_down}): ordering of goal or landmark facts\r\n - original: according to their (internal) variable index\r\n - random: according to a random permutation\r\n - hadd_up: according to their h^add value, lowest first\r\n - hadd_down: according to their h^add value, highest first \r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n== landmarks ==\r\nlandmarks(order=hadd_down, random_seed=-1, combine_facts=true)\r\n order ({original, random, hadd_up, hadd_down}): ordering of goal or landmark facts\r\n - original: according to their (internal) variable index\r\n - random: according to a random permutation\r\n - hadd_up: according to their h^add value, lowest first\r\n - hadd_down: according to their h^add value, highest first \r\n random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.\r\n combine_facts (bool): combine landmark facts with domain abstraction\r\n== original ==\r\noriginal(copies=1)\r\n copies (int [1, infinity]): number of task copies\r\n\r\nHelp output finished.\r\n"